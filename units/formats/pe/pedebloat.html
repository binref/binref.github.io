<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.11.6" />
<title>the refinery.units.formats.pe.pedebloat documentation</title>
<meta name="description" content="On a Mission to Refine Binaries" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow-night-bright.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{background-color:#0D0D0D;color:#EEEEEE;font-size:16pt}@font-face{font-family:"FixedSysEx";src:local('Fixedsys Excelsior 3.01-L2'),local('Fixedsys Excelsior 3.01'),local('FixedSysEx'),url(../../../FixedSysEx.ttf) format('truetype')}code,pre,body,html{font-family:FixedSysEx,monospace}b,strong{font-weight:normal}#content{padding:20px}#sidebar{padding:1vw;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #EEEEEE;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}hr{display:none}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#EE8080;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#EEEEEE}// .title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#BB4040}pre code{background:#000000;display:block;padding:1px 0px 4px 0px;line-height:100%}code{background:#000000;padding:1px 0px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#000000;border:0;border-top:1px solid #EEEEEE;border-bottom:1px solid #EEEEEE;margin:1em 0;padding:1ex;overflow-x:auto}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index ul{list-style-type:square;padding:0}// #index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 10px}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#000000;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#0D0D0D}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#EEEEEE;border-left:5px solid #EEEEEE;padding-left:1em}.inheritance em{font-style:normal}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1ch}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition.note,.admonition.info,.admonition.todo,.admonition.versionadded,.admonition.important,.admonition.tip,.admonition.hint{background:#054000}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#998800}.admonition.error,.admonition.danger,.admonition.caution{background:#300000}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:1vw}main{display:flex;flex-direction:row;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #EEEEEE;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>refinery.units.formats.pe.pedebloat</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/binref/refinery/blob/4c0004e3a5e038a14f699905f942361689d71fc3/refinery/units/formats/pe/pedebloat.py#L1-L356" class="git-link">Browse git</a>
</summary>
<pre><code class="python">from __future__ import annotations

import zlib

from fnmatch import fnmatch
from typing import TYPE_CHECKING, Generator, Iterable

from refinery.lib.executable import Executable
from refinery.lib.meta import SizeInt
from refinery.lib.meta import TerseSizeInt as TI
from refinery.lib.shared.pefile import pefile
from refinery.lib.types import Param
from refinery.units.formats.pe import Arg, OverlayUnit
from refinery.units.formats.pe.perc import RSRC

if TYPE_CHECKING:
    from pefile import PE, SectionStructure, Structure


_KB = 1000
_MB = _KB * _KB

_STRIP = TI(10 * _MB)
_ASCII = Executable.ascii


class BrokenLink(Exception):
    pass


class pedebloat(OverlayUnit):
    &#34;&#34;&#34;
    Removes junk or excess data from PE files and returns the stripped executable. By default, only
    the PE overlay is considered; use the flags `-r` and `-s` to also consider resources and entire
    sections. Any buffer is only considered for removal if it exceeds a certain size. If this
    condition is met, a binary search is performed to determine the offset inside the buffer up to
    which the compression ratio is above a certain threshold; everything beyond that point is then
    removed. By setting the threshold compression ratio to 1, each large buffer is removed entirely.
    &#34;&#34;&#34;
    def __init__(
        self,
        *names: Param[str, Arg.String()],
        certificate=False,
        directories=False,
        memdump=False,
        resources: Param[bool, Arg.Switch(&#39;-r&#39;, help=&#39;Strip large resources.&#39;)] = False,
        sections: Param[bool, Arg.Switch(&#39;-s&#39;, help=&#39;Strip large sections.&#39;)] = False,
        trim_code: Param[bool, Arg.Switch(&#39;-X&#39;, help=&#39;Lift the exception on code sections for stripping.&#39;)] = False,
        trim_rsrc: Param[bool, Arg.Switch(&#39;-Y&#39;, help=&#39;Lift the exception on rsrc sections for stripping.&#39;)] = False,
        threshold: Param[float, Arg.Double(&#39;-t&#39;, metavar=&#39;T&#39;, help=(
            &#39;Trailing data from resources and sections is stripped until the compression ratio &#39;
            &#39;of the remaining data rises above this threshold. The default value is {default}. &#39;
            &#39;Set this to 1 to ignore the limit entirely and trim every structure as much as &#39;
            &#39;possible without violating alignment. Setting this value to 0 will only strip repeated &#39;
            &#39;occurrences of the last byte.&#39;))] = 0.05,
        size_limit: Param[int, Arg.Number(&#39;-l&#39;, help=(
            &#39;Structures below this size are not stripped. Default is {default!r}.&#39;))] = _STRIP,
        keep_limit: Param[bool, Arg.Switch(&#39;-k&#39;, help=(
            &#39;Do not strip structures to below the above size limit.&#39;))] = False,
        aggressive: Param[bool, Arg.Switch(&#39;-a&#39;, help=(
            &#39;Equivalent to -srt1: Strip large sections and resources aggressively.&#39;))] = False,
    ):
        if aggressive:
            sections = True
            resources = True
            threshold = 1

        super().__init__(
            certificate,
            directories,
            memdump,
            sections=sections,
            resources=resources,
            size_limit=size_limit,
            keep_limit=keep_limit,
            threshold=threshold,
            trim_rsrc=trim_rsrc,
            trim_code=trim_code,
            names=names,
        )

    def _right_strip_data(self, data: memoryview, alignment=1, block_size=_MB) -&gt; int:
        if not data:
            return 0
        threshold = self.args.threshold
        data_overhang = len(data) % alignment
        result = data_overhang

        if 0 &lt; threshold &lt; 1:
            def compression_ratio(offset: int):
                ratio = len(zlib.compress(data[:offset], level=1)) / offset
                self.log_debug(F&#39;compressing {SizeInt(offset)!r} ratio={ratio:6.4f}&#39;)
                return ratio
            upper = len(data)
            lower = result
            if compression_ratio(upper) &lt;= threshold:
                while block_size &lt; upper - lower:
                    pivot = (lower + upper) // 2
                    ratio = compression_ratio(pivot)
                    if ratio &gt; threshold:
                        lower = pivot + 1
                        continue
                    upper = pivot
                    if abs(ratio - threshold) &lt; 1e-10:
                        break
            result = upper
        elif threshold == 0:
            result = len(data)
        elif threshold == 1:
            result = 0

        while result &gt; 1 and data[result - 2] == data[result - 1]:
            result -= 1

        result = max(result, data_overhang)

        if self.args.keep_limit:
            result = max(result, self.args.size_limit)

        result = result + (data_overhang - result) % alignment

        if result &gt; len(data):
            excess = result - len(data)
            excess = excess + (-excess % alignment)
            result = result - excess

        return result

    def _adjust_offsets(self, pe: PE, gap_offset: int, gap_size: int):
        base = pe.OPTIONAL_HEADER.ImageBase
        alignment = pe.OPTIONAL_HEADER.FileAlignment
        rva_offset = pe.get_rva_from_offset(gap_offset)
        tva_offset = rva_offset + base

        section = pe.get_section_by_offset(gap_offset)
        new_section_size = section.SizeOfRawData - gap_size
        if new_section_size % alignment != 0:
            raise RuntimeError(
                F&#39;trimming 0x{gap_size:X} bytes from section {_ASCII(section.Name)} of size 0x{section.SizeOfRawData:X} &#39;
                F&#39;violates required section alignment of 0x{alignment:X} bytes&#39;)
        inside_section_offset = gap_offset - section.PointerToRawData
        if inside_section_offset &gt; new_section_size:
            overlap = inside_section_offset - new_section_size
            raise RuntimeError(F&#39;trimming from section {_ASCII(section.Name)}; data extends {overlap} beyond section&#39;)

        rva_lbound = section.VirtualAddress
        rva_ubound = section.VirtualAddress + section.Misc_VirtualSize - 1
        tva_lbound = rva_lbound + base
        tva_ubound = rva_ubound + base

        def adjust_attributes_of_structure(
            structure: Structure,
            gap_offset: int,
            valid_values_lower_bound: int | None,
            valid_values_upper_bound: int | None,
            attributes: Iterable[str]
        ):
            for attribute in attributes:
                old_value = getattr(structure, attribute, 0)
                if old_value &lt;= gap_offset:
                    continue
                if valid_values_lower_bound is not None and old_value &lt; valid_values_lower_bound:
                    continue
                if valid_values_upper_bound is not None and old_value &gt; valid_values_upper_bound:
                    continue
                new_value = old_value - gap_size
                if new_value &lt; gap_offset:
                    raise BrokenLink(F&#39;attribute {attribute} points into removed region&#39;)
                self.log_debug(F&#39;adjusting field in {structure.name}: {attribute}&#39;)
                setattr(structure, attribute, new_value)

        it: Iterable[Structure] = iter(pe.__structures__)
        structure_class = pefile.SectionStructure
        remove = []

        for index, structure in enumerate(it):
            old_offset = structure.get_file_offset()
            new_offset = old_offset - gap_offset

            if old_offset &gt; gap_offset:
                if old_offset &lt; gap_offset + gap_size:
                    self.log_debug(F&#39;removing structure {structure.name}; starts inside removed region&#39;)
                    remove.append(index)
                    continue
                if isinstance(structure, structure_class) and new_offset % alignment != 0:
                    raise RuntimeError(
                        F&#39;structure {structure.name} would be moved to offset 0x{new_offset:X}, &#39;
                        F&#39;violating section alignment value 0x{alignment:X}.&#39;)
                structure.set_file_offset(new_offset)

            try:
                adjust_attributes_of_structure(structure, rva_offset, rva_lbound, rva_ubound, (
                    &#39;OffsetToData&#39;,
                    &#39;AddressOfData&#39;,
                    &#39;VirtualAddress&#39;,
                    &#39;AddressOfNames&#39;,
                    &#39;AddressOfNameOrdinals&#39;,
                    &#39;AddressOfFunctions&#39;,
                    &#39;AddressOfEntryPoint&#39;,
                    &#39;AddressOfRawData&#39;,
                    &#39;BaseOfCode&#39;,
                    &#39;BaseOfData&#39;,
                ))
                adjust_attributes_of_structure(structure, tva_offset, tva_lbound, tva_ubound, (
                    &#39;StartAddressOfRawData&#39;,
                    &#39;EndAddressOfRawData&#39;,
                    &#39;AddressOfIndex&#39;,
                    &#39;AddressOfCallBacks&#39;,
                ))
                adjust_attributes_of_structure(structure, gap_offset, None, None, (
                    &#39;OffsetModuleName&#39;,
                    &#39;PointerToRawData&#39;,
                ))
            except BrokenLink as error:
                self.log_debug(F&#39;removing structure {structure.name}; {error!s}&#39;)
                remove.append(index)
                continue

            for attribute in (
                &#39;CvHeaderOffset&#39;,
                &#39;OffsetIn2Qwords&#39;,
                &#39;OffsetInQwords&#39;,
                &#39;Offset&#39;,
                &#39;OffsetLow&#39;,
                &#39;OffsetHigh&#39;
            ):
                if not hasattr(structure, attribute):
                    continue
                self.log_warn(F&#39;potential offset in structure {structure.name} ignored: {attribute}&#39;)

        while remove:
            index = remove.pop()
            pe.__structures__[index:index + 1] = []

        section.SizeOfRawData = new_section_size

    def _trim_sections(self, pe: PE, data: bytearray) -&gt; int:
        S = self.args.size_limit
        P = self.args.names
        trimmed = 0
        for section in pe.sections:
            section: SectionStructure
            offset = section.PointerToRawData
            name = _ASCII(section.Name)
            if not self.args.trim_code and name.lower() in (&#39;.text&#39;, &#39;.code&#39;):
                self.log_debug(F&#39;skipping code section {name}; specify --trim-code to override.&#39;)
                continue
            if not self.args.trim_rsrc and name.lower() == &#39;.rsrc&#39;:
                self.log_debug(F&#39;skipping rsrc section {name}; specify --trim-rsrc to override.&#39;)
                continue
            old_size = section.SizeOfRawData
            if old_size &lt;= S and not any(fnmatch(name, p) for p in P):
                self.log_debug(F&#39;criteria not satisfied for section: {SizeInt(old_size)!r} {name}&#39;)
                continue
            new_size = self._right_strip_data(
                memoryview(data)[offset:offset + old_size],
                pe.OPTIONAL_HEADER.FileAlignment)
            if new_size == old_size:
                continue
            self.log_info(F&#39;stripping section {name} from {TI(old_size)!r} to {TI(new_size)!r}&#39;)
            gap_size = old_size - new_size
            gap_offset = offset + new_size
            if gap_size &lt;= 0:
                continue
            self._adjust_offsets(pe, gap_offset, gap_size)
            trimmed += gap_size
            data[gap_offset:gap_offset + gap_size] = []
        return trimmed

    def _trim_pe_resources(self, pe: PE, data: bytearray) -&gt; int:
        S = self.args.size_limit
        P = self.args.names
        trimmed = 0

        def find_bloated_resources(pe: PE, directory, level: int = 0, *path) -&gt; Generator[Structure]:
            for entry in directory.entries:
                name = getattr(entry, &#39;name&#39;)
                numeric = getattr(entry, &#39;id&#39;)
                if not name:
                    if level == 0 and numeric in iter(RSRC):
                        name = RSRC(entry.id)
                    elif numeric is not None:
                        name = str(numeric)
                name = name and str(name) or &#39;?&#39;
                if entry.struct.DataIsDirectory:
                    yield from find_bloated_resources(pe, entry.directory, level + 1, *path, name)
                    continue
                struct: Structure = entry.data.struct
                name = &#39;/&#39;.join((*path, name))
                if struct.Size &lt;= S and not any(fnmatch(name, p) for p in P):
                    self.log_debug(F&#39;criteria not satisfied for resource: {SizeInt(struct.Size)!r} {name}&#39;)
                    continue
                yield name, struct

        RSRC_INDEX = pefile.DIRECTORY_ENTRY[&#39;IMAGE_DIRECTORY_ENTRY_RESOURCE&#39;]
        pe.parse_data_directories(directories=[RSRC_INDEX])

        try:
            resources = pe.DIRECTORY_ENTRY_RESOURCE
        except AttributeError:
            return 0
        for name, resource in find_bloated_resources(pe, resources):
            offset = pe.get_offset_from_rva(resource.OffsetToData)
            old_size = resource.Size
            new_size = self._right_strip_data(
                memoryview(data)[offset:offset + old_size],
                pe.OPTIONAL_HEADER.FileAlignment)
            self.log_info(F&#39;stripping resource {name} from {old_size} to {new_size}&#39;)
            gap_size = old_size - new_size
            gap_offset = offset + new_size
            if gap_size &lt;= 0:
                continue
            resource.Size = new_size
            self._adjust_offsets(pe, gap_offset, gap_size)
            trimmed += gap_size
            data[gap_offset:gap_offset + gap_size] = []

        pe.OPTIONAL_HEADER.DATA_DIRECTORY[RSRC_INDEX].Size -= trimmed
        self.log_info(F&#39;trimming size of resource data directory by {TI(trimmed)!r}&#39;)
        return trimmed

    def process(self, data: bytearray) -&gt; bytearray:
        overlay_offset = self._get_size(data)
        if len(data) - overlay_offset &gt;= self.args.size_limit:
            view = memoryview(data)
            overlay_length = self._right_strip_data(view[overlay_offset:])
            body_size = overlay_offset + overlay_length
            try:
                data[body_size:] = []
            except Exception:
                data = data[:body_size]
        if not self.args.resources and not self.args.sections:
            return data
        pe = pefile.PE(data=data, fast_load=True)
        total = len(data)
        trimmed = 0
        view = pe.__data__
        copy = False
        if not isinstance(view, bytearray):
            view = memoryview(view)
            try:
                view[0] = 0x4D
            except Exception:
                copy = True
                view = bytearray(pe.__data__)
        if self.args.resources:
            trimmed += self._trim_pe_resources(pe, view)
        if self.args.sections:
            trimmed += self._trim_sections(pe, view)
        if copy:
            pe.__data__ = view
        data = pe.write()
        end = total - trimmed
        if end &lt; len(data):
            self.log_warn(F&#39;output contains {len(data) - end} trailing bytes&#39;)
        return data</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="refinery.units.formats.pe.pedebloat.BrokenLink"><code class="flex name class">
<span>class <span class="ident">BrokenLink</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Common base class for all non-exit exceptions.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/binref/refinery/blob/4c0004e3a5e038a14f699905f942361689d71fc3/refinery/units/formats/pe/pedebloat.py#L27-L28" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class BrokenLink(Exception):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="refinery.units.formats.pe.pedebloat.pedebloat"><code class="flex name class">
<span>class <span class="ident">pedebloat</span></span>
<span>(</span><span>*names, certificate=False, directories=False, memdump=False, resources=False, sections=False, trim_code=False, trim_rsrc=False, threshold=0.05, size_limit=10.0 MB, keep_limit=False, aggressive=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes junk or excess data from PE files and returns the stripped executable. By default, only
the PE overlay is considered; use the flags <code>-r</code> and <code>-s</code> to also consider resources and entire
sections. Any buffer is only considered for removal if it exceeds a certain size. If this
condition is met, a binary search is performed to determine the offset inside the buffer up to
which the compression ratio is above a certain threshold; everything beyond that point is then
removed. By setting the threshold compression ratio to 1, each large buffer is removed entirely.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/binref/refinery/blob/4c0004e3a5e038a14f699905f942361689d71fc3/refinery/units/formats/pe/pedebloat.py#L31-L356" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class pedebloat(OverlayUnit):
    &#34;&#34;&#34;
    Removes junk or excess data from PE files and returns the stripped executable. By default, only
    the PE overlay is considered; use the flags `-r` and `-s` to also consider resources and entire
    sections. Any buffer is only considered for removal if it exceeds a certain size. If this
    condition is met, a binary search is performed to determine the offset inside the buffer up to
    which the compression ratio is above a certain threshold; everything beyond that point is then
    removed. By setting the threshold compression ratio to 1, each large buffer is removed entirely.
    &#34;&#34;&#34;
    def __init__(
        self,
        *names: Param[str, Arg.String()],
        certificate=False,
        directories=False,
        memdump=False,
        resources: Param[bool, Arg.Switch(&#39;-r&#39;, help=&#39;Strip large resources.&#39;)] = False,
        sections: Param[bool, Arg.Switch(&#39;-s&#39;, help=&#39;Strip large sections.&#39;)] = False,
        trim_code: Param[bool, Arg.Switch(&#39;-X&#39;, help=&#39;Lift the exception on code sections for stripping.&#39;)] = False,
        trim_rsrc: Param[bool, Arg.Switch(&#39;-Y&#39;, help=&#39;Lift the exception on rsrc sections for stripping.&#39;)] = False,
        threshold: Param[float, Arg.Double(&#39;-t&#39;, metavar=&#39;T&#39;, help=(
            &#39;Trailing data from resources and sections is stripped until the compression ratio &#39;
            &#39;of the remaining data rises above this threshold. The default value is {default}. &#39;
            &#39;Set this to 1 to ignore the limit entirely and trim every structure as much as &#39;
            &#39;possible without violating alignment. Setting this value to 0 will only strip repeated &#39;
            &#39;occurrences of the last byte.&#39;))] = 0.05,
        size_limit: Param[int, Arg.Number(&#39;-l&#39;, help=(
            &#39;Structures below this size are not stripped. Default is {default!r}.&#39;))] = _STRIP,
        keep_limit: Param[bool, Arg.Switch(&#39;-k&#39;, help=(
            &#39;Do not strip structures to below the above size limit.&#39;))] = False,
        aggressive: Param[bool, Arg.Switch(&#39;-a&#39;, help=(
            &#39;Equivalent to -srt1: Strip large sections and resources aggressively.&#39;))] = False,
    ):
        if aggressive:
            sections = True
            resources = True
            threshold = 1

        super().__init__(
            certificate,
            directories,
            memdump,
            sections=sections,
            resources=resources,
            size_limit=size_limit,
            keep_limit=keep_limit,
            threshold=threshold,
            trim_rsrc=trim_rsrc,
            trim_code=trim_code,
            names=names,
        )

    def _right_strip_data(self, data: memoryview, alignment=1, block_size=_MB) -&gt; int:
        if not data:
            return 0
        threshold = self.args.threshold
        data_overhang = len(data) % alignment
        result = data_overhang

        if 0 &lt; threshold &lt; 1:
            def compression_ratio(offset: int):
                ratio = len(zlib.compress(data[:offset], level=1)) / offset
                self.log_debug(F&#39;compressing {SizeInt(offset)!r} ratio={ratio:6.4f}&#39;)
                return ratio
            upper = len(data)
            lower = result
            if compression_ratio(upper) &lt;= threshold:
                while block_size &lt; upper - lower:
                    pivot = (lower + upper) // 2
                    ratio = compression_ratio(pivot)
                    if ratio &gt; threshold:
                        lower = pivot + 1
                        continue
                    upper = pivot
                    if abs(ratio - threshold) &lt; 1e-10:
                        break
            result = upper
        elif threshold == 0:
            result = len(data)
        elif threshold == 1:
            result = 0

        while result &gt; 1 and data[result - 2] == data[result - 1]:
            result -= 1

        result = max(result, data_overhang)

        if self.args.keep_limit:
            result = max(result, self.args.size_limit)

        result = result + (data_overhang - result) % alignment

        if result &gt; len(data):
            excess = result - len(data)
            excess = excess + (-excess % alignment)
            result = result - excess

        return result

    def _adjust_offsets(self, pe: PE, gap_offset: int, gap_size: int):
        base = pe.OPTIONAL_HEADER.ImageBase
        alignment = pe.OPTIONAL_HEADER.FileAlignment
        rva_offset = pe.get_rva_from_offset(gap_offset)
        tva_offset = rva_offset + base

        section = pe.get_section_by_offset(gap_offset)
        new_section_size = section.SizeOfRawData - gap_size
        if new_section_size % alignment != 0:
            raise RuntimeError(
                F&#39;trimming 0x{gap_size:X} bytes from section {_ASCII(section.Name)} of size 0x{section.SizeOfRawData:X} &#39;
                F&#39;violates required section alignment of 0x{alignment:X} bytes&#39;)
        inside_section_offset = gap_offset - section.PointerToRawData
        if inside_section_offset &gt; new_section_size:
            overlap = inside_section_offset - new_section_size
            raise RuntimeError(F&#39;trimming from section {_ASCII(section.Name)}; data extends {overlap} beyond section&#39;)

        rva_lbound = section.VirtualAddress
        rva_ubound = section.VirtualAddress + section.Misc_VirtualSize - 1
        tva_lbound = rva_lbound + base
        tva_ubound = rva_ubound + base

        def adjust_attributes_of_structure(
            structure: Structure,
            gap_offset: int,
            valid_values_lower_bound: int | None,
            valid_values_upper_bound: int | None,
            attributes: Iterable[str]
        ):
            for attribute in attributes:
                old_value = getattr(structure, attribute, 0)
                if old_value &lt;= gap_offset:
                    continue
                if valid_values_lower_bound is not None and old_value &lt; valid_values_lower_bound:
                    continue
                if valid_values_upper_bound is not None and old_value &gt; valid_values_upper_bound:
                    continue
                new_value = old_value - gap_size
                if new_value &lt; gap_offset:
                    raise BrokenLink(F&#39;attribute {attribute} points into removed region&#39;)
                self.log_debug(F&#39;adjusting field in {structure.name}: {attribute}&#39;)
                setattr(structure, attribute, new_value)

        it: Iterable[Structure] = iter(pe.__structures__)
        structure_class = pefile.SectionStructure
        remove = []

        for index, structure in enumerate(it):
            old_offset = structure.get_file_offset()
            new_offset = old_offset - gap_offset

            if old_offset &gt; gap_offset:
                if old_offset &lt; gap_offset + gap_size:
                    self.log_debug(F&#39;removing structure {structure.name}; starts inside removed region&#39;)
                    remove.append(index)
                    continue
                if isinstance(structure, structure_class) and new_offset % alignment != 0:
                    raise RuntimeError(
                        F&#39;structure {structure.name} would be moved to offset 0x{new_offset:X}, &#39;
                        F&#39;violating section alignment value 0x{alignment:X}.&#39;)
                structure.set_file_offset(new_offset)

            try:
                adjust_attributes_of_structure(structure, rva_offset, rva_lbound, rva_ubound, (
                    &#39;OffsetToData&#39;,
                    &#39;AddressOfData&#39;,
                    &#39;VirtualAddress&#39;,
                    &#39;AddressOfNames&#39;,
                    &#39;AddressOfNameOrdinals&#39;,
                    &#39;AddressOfFunctions&#39;,
                    &#39;AddressOfEntryPoint&#39;,
                    &#39;AddressOfRawData&#39;,
                    &#39;BaseOfCode&#39;,
                    &#39;BaseOfData&#39;,
                ))
                adjust_attributes_of_structure(structure, tva_offset, tva_lbound, tva_ubound, (
                    &#39;StartAddressOfRawData&#39;,
                    &#39;EndAddressOfRawData&#39;,
                    &#39;AddressOfIndex&#39;,
                    &#39;AddressOfCallBacks&#39;,
                ))
                adjust_attributes_of_structure(structure, gap_offset, None, None, (
                    &#39;OffsetModuleName&#39;,
                    &#39;PointerToRawData&#39;,
                ))
            except BrokenLink as error:
                self.log_debug(F&#39;removing structure {structure.name}; {error!s}&#39;)
                remove.append(index)
                continue

            for attribute in (
                &#39;CvHeaderOffset&#39;,
                &#39;OffsetIn2Qwords&#39;,
                &#39;OffsetInQwords&#39;,
                &#39;Offset&#39;,
                &#39;OffsetLow&#39;,
                &#39;OffsetHigh&#39;
            ):
                if not hasattr(structure, attribute):
                    continue
                self.log_warn(F&#39;potential offset in structure {structure.name} ignored: {attribute}&#39;)

        while remove:
            index = remove.pop()
            pe.__structures__[index:index + 1] = []

        section.SizeOfRawData = new_section_size

    def _trim_sections(self, pe: PE, data: bytearray) -&gt; int:
        S = self.args.size_limit
        P = self.args.names
        trimmed = 0
        for section in pe.sections:
            section: SectionStructure
            offset = section.PointerToRawData
            name = _ASCII(section.Name)
            if not self.args.trim_code and name.lower() in (&#39;.text&#39;, &#39;.code&#39;):
                self.log_debug(F&#39;skipping code section {name}; specify --trim-code to override.&#39;)
                continue
            if not self.args.trim_rsrc and name.lower() == &#39;.rsrc&#39;:
                self.log_debug(F&#39;skipping rsrc section {name}; specify --trim-rsrc to override.&#39;)
                continue
            old_size = section.SizeOfRawData
            if old_size &lt;= S and not any(fnmatch(name, p) for p in P):
                self.log_debug(F&#39;criteria not satisfied for section: {SizeInt(old_size)!r} {name}&#39;)
                continue
            new_size = self._right_strip_data(
                memoryview(data)[offset:offset + old_size],
                pe.OPTIONAL_HEADER.FileAlignment)
            if new_size == old_size:
                continue
            self.log_info(F&#39;stripping section {name} from {TI(old_size)!r} to {TI(new_size)!r}&#39;)
            gap_size = old_size - new_size
            gap_offset = offset + new_size
            if gap_size &lt;= 0:
                continue
            self._adjust_offsets(pe, gap_offset, gap_size)
            trimmed += gap_size
            data[gap_offset:gap_offset + gap_size] = []
        return trimmed

    def _trim_pe_resources(self, pe: PE, data: bytearray) -&gt; int:
        S = self.args.size_limit
        P = self.args.names
        trimmed = 0

        def find_bloated_resources(pe: PE, directory, level: int = 0, *path) -&gt; Generator[Structure]:
            for entry in directory.entries:
                name = getattr(entry, &#39;name&#39;)
                numeric = getattr(entry, &#39;id&#39;)
                if not name:
                    if level == 0 and numeric in iter(RSRC):
                        name = RSRC(entry.id)
                    elif numeric is not None:
                        name = str(numeric)
                name = name and str(name) or &#39;?&#39;
                if entry.struct.DataIsDirectory:
                    yield from find_bloated_resources(pe, entry.directory, level + 1, *path, name)
                    continue
                struct: Structure = entry.data.struct
                name = &#39;/&#39;.join((*path, name))
                if struct.Size &lt;= S and not any(fnmatch(name, p) for p in P):
                    self.log_debug(F&#39;criteria not satisfied for resource: {SizeInt(struct.Size)!r} {name}&#39;)
                    continue
                yield name, struct

        RSRC_INDEX = pefile.DIRECTORY_ENTRY[&#39;IMAGE_DIRECTORY_ENTRY_RESOURCE&#39;]
        pe.parse_data_directories(directories=[RSRC_INDEX])

        try:
            resources = pe.DIRECTORY_ENTRY_RESOURCE
        except AttributeError:
            return 0
        for name, resource in find_bloated_resources(pe, resources):
            offset = pe.get_offset_from_rva(resource.OffsetToData)
            old_size = resource.Size
            new_size = self._right_strip_data(
                memoryview(data)[offset:offset + old_size],
                pe.OPTIONAL_HEADER.FileAlignment)
            self.log_info(F&#39;stripping resource {name} from {old_size} to {new_size}&#39;)
            gap_size = old_size - new_size
            gap_offset = offset + new_size
            if gap_size &lt;= 0:
                continue
            resource.Size = new_size
            self._adjust_offsets(pe, gap_offset, gap_size)
            trimmed += gap_size
            data[gap_offset:gap_offset + gap_size] = []

        pe.OPTIONAL_HEADER.DATA_DIRECTORY[RSRC_INDEX].Size -= trimmed
        self.log_info(F&#39;trimming size of resource data directory by {TI(trimmed)!r}&#39;)
        return trimmed

    def process(self, data: bytearray) -&gt; bytearray:
        overlay_offset = self._get_size(data)
        if len(data) - overlay_offset &gt;= self.args.size_limit:
            view = memoryview(data)
            overlay_length = self._right_strip_data(view[overlay_offset:])
            body_size = overlay_offset + overlay_length
            try:
                data[body_size:] = []
            except Exception:
                data = data[:body_size]
        if not self.args.resources and not self.args.sections:
            return data
        pe = pefile.PE(data=data, fast_load=True)
        total = len(data)
        trimmed = 0
        view = pe.__data__
        copy = False
        if not isinstance(view, bytearray):
            view = memoryview(view)
            try:
                view[0] = 0x4D
            except Exception:
                copy = True
                view = bytearray(pe.__data__)
        if self.args.resources:
            trimmed += self._trim_pe_resources(pe, view)
        if self.args.sections:
            trimmed += self._trim_sections(pe, view)
        if copy:
            pe.__data__ = view
        data = pe.write()
        end = total - trimmed
        if end &lt; len(data):
            self.log_warn(F&#39;output contains {len(data) - end} trailing bytes&#39;)
        return data</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="refinery.units.formats.pe.OverlayUnit" href="index.html#refinery.units.formats.pe.OverlayUnit">OverlayUnit</a></li>
<li><a title="refinery.units.Unit" href="../../index.html#refinery.units.Unit">Unit</a></li>
<li><a title="refinery.units.UnitBase" href="../../index.html#refinery.units.UnitBase">UnitBase</a></li>
<li><a title="refinery.units.Entry" href="../../index.html#refinery.units.Entry">Entry</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="refinery.units.formats.pe.pedebloat.pedebloat" href="#refinery.units.formats.pe.pedebloat.pedebloat">pedebloat</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="refinery.units.formats.pe.pedebloat.pedebloat.reverse"><code class="name">var <span class="ident">reverse</span></code></dt>
<dd>
<section class="desc"><p>The type of the None singleton.</p></section>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="refinery.units.formats.pe.OverlayUnit" href="index.html#refinery.units.formats.pe.OverlayUnit">OverlayUnit</a></b></code>:
<ul class="hlist">
<li><code><a title="refinery.units.formats.pe.OverlayUnit.FilterEverything" href="../../index.html#refinery.units.UnitBase.FilterEverything">FilterEverything</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.Requires" href="../../index.html#refinery.units.Unit.Requires">Requires</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.act" href="../../index.html#refinery.units.Unit.act">act</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.assemble" href="../../index.html#refinery.units.Unit.assemble">assemble</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.codec" href="../../index.html#refinery.units.Unit.codec">codec</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.console" href="../../index.html#refinery.units.Unit.console">console</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.filter" href="../../index.html#refinery.units.UnitBase.filter">filter</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.finish" href="../../index.html#refinery.units.UnitBase.finish">finish</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.handles" href="../../index.html#refinery.units.UnitBase.handles">handles</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.is_quiet" href="../../index.html#refinery.units.Unit.is_quiet">is_quiet</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.is_reversible" href="../../index.html#refinery.units.Unit.is_reversible">is_reversible</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.isatty" href="../../index.html#refinery.units.Unit.isatty">isatty</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.labelled" href="../../index.html#refinery.units.Unit.labelled">labelled</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.leniency" href="../../index.html#refinery.units.Unit.leniency">leniency</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.log_always" href="../../index.html#refinery.units.Unit.log_always">log_always</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.log_debug" href="../../index.html#refinery.units.Unit.log_debug">log_debug</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.log_detach" href="../../index.html#refinery.units.Unit.log_detach">log_detach</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.log_fail" href="../../index.html#refinery.units.Unit.log_fail">log_fail</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.log_info" href="../../index.html#refinery.units.Unit.log_info">log_info</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.log_level" href="../../index.html#refinery.units.Unit.log_level">log_level</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.log_warn" href="../../index.html#refinery.units.Unit.log_warn">log_warn</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.logger" href="../../index.html#refinery.units.Unit.logger">logger</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.name" href="../../index.html#refinery.units.Unit.name">name</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.nozzle" href="../../index.html#refinery.units.Unit.nozzle">nozzle</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.optional_dependencies" href="../../index.html#refinery.units.Unit.optional_dependencies">optional_dependencies</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.process" href="../../index.html#refinery.units.UnitBase.process">process</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.read" href="../../index.html#refinery.units.Unit.read">read</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.read1" href="../../index.html#refinery.units.Unit.read1">read1</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.required_dependencies" href="../../index.html#refinery.units.Unit.required_dependencies">required_dependencies</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.reset" href="../../index.html#refinery.units.Unit.reset">reset</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.run" href="../../index.html#refinery.units.Unit.run">run</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.source" href="../../index.html#refinery.units.Unit.source">source</a></code></li>
<li><code><a title="refinery.units.formats.pe.OverlayUnit.superinit" href="../../index.html#refinery.units.Unit.superinit">superinit</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="refinery.units.formats.pe" href="index.html">refinery.units.formats.pe</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="refinery.units.formats.pe.pedebloat.BrokenLink" href="#refinery.units.formats.pe.pedebloat.BrokenLink">BrokenLink</a></code></h4>
</li>
<li>
<h4><code><a title="refinery.units.formats.pe.pedebloat.pedebloat" href="#refinery.units.formats.pe.pedebloat.pedebloat">pedebloat</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>
hljs.configure({languages: []})
hljs.initHighlightingOnLoad()
</script>
</body>
</html>
